{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import audio2numpy as a2n\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## recording an audio file\n",
    "duration= 5 # sec\n",
    "fs= 16000 # sample rate\n",
    "myrecord= sd.rec(int(duration * fs), samplerate= fs, channels= 1)\n",
    "# print(\"Finised Recording\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrecord[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking weather recording finished or not\n",
    "sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## palying an audio file\n",
    "sd.play(myrecord, samplerate= fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myrecord2=[]\n",
    "# for i in range(60):\n",
    "#     myrecord2.append(myrecord[fs*i:fs*(i+1)])\n",
    "myrecord2= [myrecord[fs*i:fs*(i+1)] for i in range(duration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(myrecord2)\n",
    "sd.play(myrecord2[3], samplerate=fs)\n",
    "# print(myrecord2[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(myrecord)\n",
    "len(myrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs= 16000\n",
    "n= duration\n",
    "myrecord1= myrecord[fs*n:fs*(n+1)]\n",
    "sd.play(myrecord1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= 'F:\\\\Downloads\\\\Documents\\\\Cough Detector\\\\Segmented Flusense Data\\\\train\\Cough\\\\0__-_5kbw2Mcw_cough-2.wav'\n",
    "data, fs = sf.read(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44096,)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.play(data, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import display\n",
    "# import librosa, librosa.display\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from jupyter_client.manager import KernelManager\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio\n",
    "#\n",
    "from skimage.transform import resize\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.callbacks import  ModelCheckpoint\n",
    "from keras.layers import *\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras.activations import sigmoid, tanh\n",
    "import random\n",
    "from keras.metrics import *\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ = 5\n",
    "batch_size= 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes= [\"Not_Cough\", \"Cough\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_wav_16k_mono(filename):\n",
    "#     \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "#     file_contents = tf.io.read_file(filename)\n",
    "#     wav, sample_rate = tf.audio.decode_wav(\n",
    "#         file_contents,\n",
    "#         desired_channels=1)\n",
    "#     wav = tf.squeeze(wav, axis=-1)\n",
    "#     sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "#     wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "#     return wav\n",
    "\n",
    "def load_wav_16k_mono(audio_file, sr):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\" \n",
    "    wav= audio_file\n",
    "    sample_rate= sr\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "# def load_wav_for_map(audio_file, sr, label):\n",
    "#     return load_wav_16k_mono(audio_file, sr), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15028/3656095194.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data= np.reshape(data, (data.shape[0], 1))\n",
    "data= tf.cast(data, dtype= tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x000001ACA17DBA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x000001ACA17DBA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "t_wav= load_wav_16k_mono(data, tf.cast(44100, dtype= tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## applies the embedding extraction model to a wav data\n",
    "\n",
    "def extract_embedding(wav_data, label):\n",
    "    '''run YAMNet to extract embedding from the wav data'''\n",
    "    scores, embeddings, spectrogram= yamnet_model(wav_data)\n",
    "    num_embeddings= tf.shape(embeddings)[0]\n",
    "    return (embeddings, tf.repeat(label, num_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\Asus\\AppData\\Local\\Temp\\tfhub_modules\\9616fd04ec2360621642ef9455b84f4b668e219e\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15028/2727101575.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0myamnet_model_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://tfhub.dev/google/yamnet/1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0myamnet_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myamnet_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Python Codes\\Python Projects\\Cough Detector Project\\cough_venv\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[0;32m    105\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python Codes\\Python Projects\\Cough Detector Project\\cough_venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m   \"\"\"\n\u001b[1;32m--> 900\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"root\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python Codes\\Python Projects\\Cough Detector Project\\cough_venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m   saved_model_proto, debug_info = (\n\u001b[1;32m--> 913\u001b[1;33m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
      "\u001b[1;32md:\\Python Codes\\Python Projects\\Cough Detector Project\\cough_venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m   \"\"\"\n\u001b[1;32m---> 60\u001b[1;33m   \u001b[0msaved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m   debug_info_path = file_io.join(\n",
      "\u001b[1;32md:\\Python Codes\\Python Projects\\Cough Detector Project\\cough_venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    116\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Cannot parse file {path_to_pbtxt}: {str(e)}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\Asus\\AppData\\Local\\Temp\\tfhub_modules\\9616fd04ec2360621642ef9455b84f4b668e219e\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "yamnet_model_path = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_segment (InputLayer)  [(None, 1024)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 656,642\n",
      "Trainable params: 656,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_segment= tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
    "                        name='input_segment')\n",
    "\n",
    "X= Dense(512, LeakyReLU(0.1))(input_segment)\n",
    "X= Dense(256, LeakyReLU(0.1))(X)\n",
    "output_layer= Dense(2)(X)\n",
    "\n",
    "my_model= Model(input_segment, output_layer)\n",
    "# my_model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Input(shape=(1024), dtype=tf.float32, #1024\n",
    "#                           name='input_embedding'),\n",
    "#     tf.keras.layers.Dense(512, activation='relu'),\n",
    "#     tf.keras.layers.Dense(256, activation='relu'),\n",
    "#     tf.keras.layers.Dense(len(my_classes))\n",
    "# ], name='my_model')\n",
    "\n",
    "\n",
    "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer= tf.keras.optimizers.Adam(learning_rate= 1e-5),\n",
    "                metrics=['accuracy'])\n",
    "# my_model.compile()\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "        file_contents,\n",
    "        desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "def load_wav_for_map(filename, label):\n",
    "    return load_wav_16k_mono(filename), label\n",
    "\n",
    "\n",
    "def extract_embedding(wav_data, label):\n",
    "    '''run YAMNet to extract embedding from the wav data'''\n",
    "    scores, embeddings, spectrogram= yamnet_model(wav_data)\n",
    "    num_embeddings= tf.shape(embeddings)[0]\n",
    "    return (embeddings, tf.repeat(label, num_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= 'D:\\Python Codes\\Python Projects\\Cough Detector Project\\EZTMC4Z-coughing_mono.wav'\n",
    "data, sr= sf.read(path)\n",
    "sd.play(data)\n",
    "\n",
    "du= len(data)/sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=44100>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(sr, dtype= tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x000001ACA298B550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x000001ACA298B550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "path= 'D:\\Python Codes\\Python Projects\\Cough Detector Project\\EZTMC4Z-coughing.wav'\n",
    "testing_wav_data= load_wav_16k_mono(path) #(myrecord2)\n",
    "\n",
    "duration= np.ceil(len(testing_wav_data) / 16000)\n",
    "\n",
    "# sd.play(testing_wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main sound is: Cough\n"
     ]
    }
   ],
   "source": [
    "weights_path= \"D:\\Python Codes\\Python Projects\\Cough Detector Project\\Weights\\\\try4_ep_135_val_acc_0.874.h5\" #\"/content/drive/MyDrive/Trained_Weights/pretrained_Cough_detection_YAMNet/pretrained_Cough_detection_3/keras_metadata.pb\"\n",
    "scores, embeddings, spectrogram = yamnet_model(testing_wav_data)\n",
    "# result = my_model(embeddings).numpy()\n",
    "weights= my_model.load_weights(weights_path)\n",
    "result= my_model.predict(embeddings)\n",
    "\n",
    "\n",
    "inferred_class = my_classes[result.mean(axis=0).argmax()]\n",
    "print(f'The main sound is: {inferred_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main sound is: Cough\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path= \"D:\\Python Codes\\Python Projects\\Cough Detector Project\\Weights\\\\try4_ep_135_val_acc_0.874.h5\" #\"/content/drive/MyDrive/Trained_Weights/pretrained_Cough_detection_YAMNet/pretrained_Cough_detection_3/keras_metadata.pb\"\n",
    "weights= my_model.load_weights(weights_path)\n",
    "def do_prediction(testing_wav_data):\n",
    "    scores, embeddings, spectrogram = yamnet_model(testing_wav_data)\n",
    "    result= my_model.predict(embeddings)\n",
    "    inferred_class = my_classes[result.mean(axis=0).argmax()]\n",
    "    print(f'The main sound is: {inferred_class}')\n",
    "    return result.mean(axis=0).argmax()\n",
    "\n",
    "do_prediction(t_wav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main sound is: Not_Cough\n"
     ]
    }
   ],
   "source": [
    "scores, embeddings, spectrogram = yamnet_model(tf.squeeze(myrecord2[0]))\n",
    "result= my_model.predict(embeddings)\n",
    "inferred_class = my_classes[result.mean(axis=0).argmax()]\n",
    "print(f'The main sound is: {inferred_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(t_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "The main sound is: Cough\n",
      "Cough rate is 0.5 coughs per sec\n"
     ]
    }
   ],
   "source": [
    "testing_wav_data= t_wav\n",
    "# duration= len(testing_wav_data)/\n",
    "fs= 16000\n",
    "s=2 ## do prediction over 2s audio\n",
    "cr=0\n",
    "for i in range(int(np.ceil(duration/s))):\n",
    "    temp_wav_data= testing_wav_data[fs*i:fs*(i+s)]\n",
    "    r= do_prediction(temp_wav_data)\n",
    "    cr= cr+r\n",
    "\n",
    "print(f\"Cough rate is {cr/duration} coughs per sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final assemble\n",
    "\n",
    "def config_variable():\n",
    "    fs= 16000 #smaple rate\n",
    "    sec_per_audio= 2 ## audio length for giving to prediction\n",
    "    my_classes= [\"Not_Cough\", \"Cough\"]\n",
    "\n",
    "\n",
    "\n",
    "def load_mymodel_and_weights(weights_path):\n",
    "    \"\"\" This function will load all the needed material for doing prediction like the whole model and variables\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"loading model\"\"\"\n",
    "    \n",
    "    yamnet_model_path = 'https://tfhub.dev/google/yamnet/1'\n",
    "    yamnet_model = hub.load(yamnet_model_path)\n",
    "    \n",
    "    input_segment= tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
    "                    name='input_segment')\n",
    "    X= Dense(512, LeakyReLU(0.1))(input_segment)\n",
    "    X= Dense(256, LeakyReLU(0.1))(X)\n",
    "    output_layer= Dense(2)(X)\n",
    "    my_model= Model(input_segment, output_layer)\n",
    "    \n",
    "    \n",
    "    my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    optimizer= tf.keras.optimizers.Adam(learning_rate= 1e-5),\n",
    "                    metrics=['accuracy'])\n",
    "    \n",
    "    weights= my_model.load_weights(weights_path)\n",
    "\n",
    "## This function will predict wheather the given audio file have cough or not in it. \n",
    "\n",
    "def do_prediction(testing_wav_data):\n",
    "    \n",
    "    \"\"\"Input= numpy audio file\n",
    "        output 1 if the audio have cough, 0 if not\n",
    "    \"\"\"\n",
    "    \n",
    "    scores, embeddings, spectrogram = yamnet_model(testing_wav_data)\n",
    "    result= my_model.predict(embeddings)\n",
    "    inferred_class = my_classes[result.mean(axis=0).argmax()]\n",
    "    \n",
    "    print(f'The main sound is: {inferred_class}')\n",
    "    \n",
    "    return result.mean(axis=0).argmax() ## output 1 if the audio have cough, 0 if not\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recording_audio(duration, fs=16000):\n",
    "    \"\"\"This function will record audio file for given sec\"\"\"\n",
    "    recorded_audio= sd.rec(int(duration*fs), samplerate= fs, channels= 1)\n",
    "    sd.wait()\n",
    "    return recorded_audio\n",
    "\n",
    "\n",
    "def load_wav_16k_mono(audio_file, sr):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\" \n",
    "    wav= tf.cast(audio_file, dtype= tf.float32)\n",
    "    # sample_rate= sr\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sr, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "def load_wav_for_map(audio_file, sr, label):\n",
    "    return load_wav_16k_mono(audio_file, sr), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load config\n",
    "## load the model\n",
    "## record the audio\n",
    "## convert it to segments to predict\n",
    "##\n",
    "\n",
    "\n",
    "config_variable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (Temp/ipykernel_604/3282203217.py, line 52)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_604/3282203217.py\"\u001b[1;36m, line \u001b[1;32m52\u001b[0m\n\u001b[1;33m    def load_wav_for_map(test_audio_file, sr= 16000, label):\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "## for mono channel audio file\n",
    "\n",
    "# def mono_channel_audio(audio_file):\n",
    "#     nchannels= audio_file.shape[1]\n",
    "#     return np.reshape(audio_file.sum(axis= 1)/nchannels, (audio_file.shape[0],1))\n",
    "\n",
    "\n",
    "\n",
    "# def load_wav_16k_mono(audio_file, sr= 16000):\n",
    "#     \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "#     wav= audio_file\n",
    "#     sample_rate= int(sr)\n",
    "#     wav = tf.squeeze(wav, axis=-1)\n",
    "#     sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "#     wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=tf.cast(16000, dtype= tf.int64))\n",
    "#     return wav\n",
    "\n",
    "# def load_wav_for_map(audio_file, sr= 16000, label):\n",
    "#     return load_wav_16k_mono(audio_file, sr), label\n",
    "\n",
    "\n",
    "## For loading file from internal storage\n",
    "\n",
    "# def load_wav_16k_mono(filename):\n",
    "#     \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "#     file_contents = tf.io.read_file(filename)\n",
    "#     wav, sample_rate = tf.audio.decode_wav(\n",
    "#         file_contents,\n",
    "#         desired_channels=1)\n",
    "#     wav = tf.squeeze(wav, axis=-1)\n",
    "#     sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "#     wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "#     return wav\n",
    "\n",
    "# def load_wav_for_map(audio_file, label):\n",
    "#     return load_wav_16k_mono(audio_file), label\n",
    "\n",
    "\n",
    "# def load_wav_16k_mono(audio_file, sr= 16000):\n",
    "#     \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "#     # file_contents = tf.io.read_file(filename)\n",
    "#     # wav, sample_rate = tf.audio.decode_wav(\n",
    "#     #     file_contents,\n",
    "#     #     desired_channels=1)\n",
    "#     wav= audio_file\n",
    "#     sample_rate= sr\n",
    "#     wav = tf.squeeze(wav, axis=-1)\n",
    "#     sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "#     wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "#     return wav\n",
    "\n",
    "# def load_wav_for_map(test_audio_file, sr= 16000, label):\n",
    "#     return load_wav_16k_mono(test_audio_file, sr), label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for Cough rate\n",
    "weights_path = \"D:\\Python Codes\\Python Projects\\Cough Detector Project\\Weights\\\\try4_ep_135_val_acc_0.874.h5\"\n",
    "weights = my_model.load_weights(weights_path)\n",
    "\n",
    "def cough_rate(test_audio_file, sr):\n",
    "    # \"/content/drive/MyDrive/Trained_Weights/pretrained_Cough_detection_YAMNet/pretrained_Cough_detection_3/keras_metadata.pb\"\n",
    "    \n",
    "    testing_wav_data= load_wav_16k_mono(test_audio_file, sr)\n",
    "    scores, embeddings, spectrogram = yamnet_model(testing_wav_data)\n",
    "    # result = my_model(embeddings).numpy()\n",
    "    result = my_model.predict(embeddings)\n",
    "    inferred_class = my_classes[result.mean(axis=0).argmax()]\n",
    "    # print(f'The main sound is: {inferred_class}')\n",
    "    return result.mean(axis=0).argmax()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507456,)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path= \"D:\\Python Codes\\Python Projects\\Cough Detector Project\\EZTMC4Z-coughing_mono.wav\"\n",
    "test_wav, sr= librosa.load(path) #channels= 2\n",
    "# test_wav= test_wav.reshape((test_wav.shape[0],1))\n",
    "test_wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(test_wav, samplerate= sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to load audio data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_wav, sr= librosa.load(path)\n",
    "# len(test_wav), sr\n",
    "path= \"D:\\Python Codes\\Python Projects\\Cough Detector Project\\EZTMC4Z-coughing.wav\"\n",
    "test_wav, sr= sf.read(path) #channels= 2\n",
    "# sd.play(test_wav, sr)\n",
    "# duration= int(np.ceil(len(test_wav)/sr))\n",
    "# myrecord[fs*i:fs*(i+1)] for i in range(duration)\n",
    "# duration\n",
    "nchannels= test_wav.shape[0]\n",
    "test_wav= test_wav.sum(axis=1)/nchannels\n",
    "\n",
    "# if test_wav.shape[1]== 2 :\n",
    "#     test_wav= (test_wav[:,0]+test_wav[:,1])/2\n",
    "temp= librosa.load(path, sr= 16000)\n",
    "type(list(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr= []\n",
    "fs=16000 \n",
    "for i in range(duration):\n",
    "    cr.append(cough_rate(test_wav[fs*i: fs*(i+1)], sr))\n",
    "\n",
    "cr= np.sum(cr)/duration\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_channel_audio(audio_file):\n",
    "    nchannels= audio_file.shape[1]\n",
    "    return np.reshape(audio_file.sum(axis= 1, keepdims= True)/nchannels, (audio_file.shape[0],1))\n",
    "\n",
    "path= \"D:\\Python Codes\\Python Projects\\Cough Detector Project\\EZTMC4Z-coughing.wav\"\n",
    "test_wav, sr= sf.read(path) #channels= 2\n",
    "test_wav= mono_channel_audio(test_wav)\n",
    "sf.write(\"D:\\Python Codes\\Python Projects\\Cough Detector Project\\EZTMC4Z-coughing_mono.wav\", test_wav, samplerate= sr)\n",
    "sd.play(test_wav, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.eye(3,4)\n",
    "a=a.sum(axis=0, keepdims= True)\n",
    "a.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9439a0fb42fba0afa0287734139b5de3e2c2bb21049a36cf928316e668b8c3a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
